{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9426707,"sourceType":"datasetVersion","datasetId":5584155}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics\nimport os, shutil","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T07:11:14.048609Z","iopub.execute_input":"2026-01-12T07:11:14.049397Z","iopub.status.idle":"2026-01-12T07:12:21.602180Z","shell.execute_reply.started":"2026-01-12T07:11:14.049364Z","shell.execute_reply":"2026-01-12T07:12:21.601447Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.252-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.21.0)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.252-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.252 ultralytics-thop-2.0.18\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\n# -------------------------------\n# Define paths to the C2A dataset\n# -------------------------------\nbase_path = \"/kaggle/input/c2a-dataset/C2A_Dataset/new_dataset3\"\n\ntrain_img_dir = os.path.join(base_path, \"train\", \"images\")\ntrain_lbl_dir = os.path.join(base_path, \"train\", \"labels\")\nval_img_dir   = os.path.join(base_path, \"val\", \"images\")\nval_lbl_dir   = os.path.join(base_path, \"val\", \"labels\")\n\n# ------------------------------------------\n# Create working directory (train/val/test)\n# ------------------------------------------\nwork_dir = \"/kaggle/working/flood_yolo\"\n\nfor subdir in [\n    \"images/train\", \"images/val\", \"images/test\",\n    \"labels/train\", \"labels/val\", \"labels/test\"\n]:\n    os.makedirs(os.path.join(work_dir, subdir), exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T07:12:21.603453Z","iopub.execute_input":"2026-01-12T07:12:21.603773Z","iopub.status.idle":"2026-01-12T07:12:21.609547Z","shell.execute_reply.started":"2026-01-12T07:12:21.603736Z","shell.execute_reply":"2026-01-12T07:12:21.608966Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# -------------------------------\n# Filter flood images\n# -------------------------------\nflood_train_imgs = [\n    f for f in os.listdir(train_img_dir)\n    if f.startswith(\"flood_image\")\n]\n\nflood_val_imgs = [\n    f for f in os.listdir(val_img_dir)\n    if f.startswith(\"flood_image\")\n]\n\nprint(\n    f\"Found {len(flood_train_imgs)} flood training images and \"\n    f\"{len(flood_val_imgs)} flood validation images.\"\n)\n\n\n# ------------------------------------------\n# Split validation â†’ val (80%) + test (20%)\n# ------------------------------------------\nrandom.seed(42)  # reproducibility\n\nnum_test = max(1, int(0.20 * len(flood_val_imgs)))\ntest_imgs = random.sample(flood_val_imgs, num_test)\nval_imgs_final = list(set(flood_val_imgs) - set(test_imgs))\n\nprint(f\"Validation images: {len(val_imgs_final)}\")\nprint(f\"Test images: {len(test_imgs)}\")\n\n# -------------------------------\n# Copy training images\n# -------------------------------\nfor img_file in flood_train_imgs:\n    src_img = os.path.join(train_img_dir, img_file)\n    src_lbl = os.path.join(train_lbl_dir, img_file.replace(\".png\", \".txt\"))\n\n    dst_img = os.path.join(work_dir, \"images/train\", img_file)\n    dst_lbl = os.path.join(work_dir, \"labels/train\", img_file.replace(\".png\", \".txt\"))\n\n    shutil.copy(src_img, dst_img)\n    shutil.copy(src_lbl, dst_lbl)\n\n# -------------------------------\n# Copy validation images (80%)\n# -------------------------------\nfor img_file in val_imgs_final:\n    src_img = os.path.join(val_img_dir, img_file)\n    src_lbl = os.path.join(val_lbl_dir, img_file.replace(\".png\", \".txt\"))\n\n    dst_img = os.path.join(work_dir, \"images/val\", img_file)\n    dst_lbl = os.path.join(work_dir, \"labels/val\", img_file.replace(\".png\", \".txt\"))\n\n    shutil.copy(src_img, dst_img)\n    shutil.copy(src_lbl, dst_lbl)\n\n# -------------------------------\n# Copy test images (20%)\n# -------------------------------\nfor img_file in test_imgs:\n    src_img = os.path.join(val_img_dir, img_file)\n    src_lbl = os.path.join(val_lbl_dir, img_file.replace(\".png\", \".txt\"))\n\n    dst_img = os.path.join(work_dir, \"images/test\", img_file)\n    dst_lbl = os.path.join(work_dir, \"labels/test\", img_file.replace(\".png\", \".txt\"))\n\n    shutil.copy(src_img, dst_img)\n    shutil.copy(src_lbl, dst_lbl)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T07:12:21.610733Z","iopub.execute_input":"2026-01-12T07:12:21.611123Z","iopub.status.idle":"2026-01-12T07:13:00.069080Z","shell.execute_reply.started":"2026-01-12T07:12:21.611097Z","shell.execute_reply":"2026-01-12T07:13:00.068329Z"}},"outputs":[{"name":"stdout","text":"Found 1529 flood training images and 542 flood validation images.\nValidation images: 434\nTest images: 108\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# -------------------------------\n# Create dataset YAML\n# -------------------------------\ndataset_yaml = f\"\"\"\npath: {work_dir}\ntrain: images/train\nval: images/val\ntest: images/test\nnames:\n  0: human\n\"\"\"\n\nyaml_path = os.path.join(work_dir, \"flood.yaml\")\nwith open(yaml_path, \"w\") as f:\n    f.write(dataset_yaml)\n\nprint(\"Flood-only dataset YAML created at\", yaml_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T07:13:00.070761Z","iopub.execute_input":"2026-01-12T07:13:00.071035Z","iopub.status.idle":"2026-01-12T07:13:00.076414Z","shell.execute_reply.started":"2026-01-12T07:13:00.071017Z","shell.execute_reply":"2026-01-12T07:13:00.075888Z"}},"outputs":[{"name":"stdout","text":"Flood-only dataset YAML created at /kaggle/working/flood_yolo/flood.yaml\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"from ultralytics import YOLO\n# Load pretrained RT-DETR (official HF version)\nmodel = YOLO('rtdetr-l.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T07:13:00.077055Z","iopub.execute_input":"2026-01-12T07:13:00.077233Z","iopub.status.idle":"2026-01-12T07:13:06.600551Z","shell.execute_reply.started":"2026-01-12T07:13:00.077219Z","shell.execute_reply":"2026-01-12T07:13:06.599938Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file âœ… \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"results = model.train(\n    data=os.path.join(work_dir, \"flood.yaml\"),  # use the flood-only dataset\n    epochs=100,\n    batch=4,\n    imgsz=960,\n    workers=2,\n    lr0=0.01,               # Initial learning rate\n    lrf=0.01,               # Final learning rate fraction (end of cosine schedule)\n    momentum=0.937,         # Momentum for optimizer\n    weight_decay=0.0005,    # Helps regularization\n    warmup_epochs=3,        # Warmup for stable initial convergence\n    augment=True,\n    #optimizer=\"AdamW\",\n    patience=25       # early stopping if no improvement\n    #close_mosaic=10,  # disable mosaic augmentation after 10 epochs\n    #degrees=20,       # augmentation: rotation range\n    #translate=0.2,    # augmentation: translation\n    #scale=0.5,        # augmentation: scale (zoom) range\n    #shear=10,         # augmentation: shear angle\n    #flipud=0.1,       # augmentation: vertical flip probability\n    #hsv_h=0.015,      # augmentation: HSV hue\n    #hsv_s=0.7,        # augmentation: HSV saturation\n    #hsv_v=0.4         # augmentation: HSV value (brightness)\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T07:13:06.601341Z","iopub.execute_input":"2026-01-12T07:13:06.601674Z","iopub.status.idle":"2026-01-12T15:48:11.696251Z","shell.execute_reply.started":"2026-01-12T07:13:06.601656Z","shell.execute_reply":"2026-01-12T15:48:11.695561Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.252 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=4, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/flood_yolo/flood.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=960, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=rtdetr-l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train13, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/train13, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 25.4MB/s 0.0s\nOverriding model.yaml nc=80 with nc=1\nWARNING âš ï¸ no model scale passed. Assuming scale='l'.\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1     25248  ultralytics.nn.modules.block.HGStem          [3, 32, 48]                   \n  1                  -1  6    155072  ultralytics.nn.modules.block.HGBlock         [48, 48, 128, 3, 6]           \n  2                  -1  1      1408  ultralytics.nn.modules.conv.DWConv           [128, 128, 3, 2, 1, False]    \n  3                  -1  6    839296  ultralytics.nn.modules.block.HGBlock         [128, 96, 512, 3, 6]          \n  4                  -1  1      5632  ultralytics.nn.modules.conv.DWConv           [512, 512, 3, 2, 1, False]    \n  5                  -1  6   1695360  ultralytics.nn.modules.block.HGBlock         [512, 192, 1024, 5, 6, True, False]\n  6                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  7                  -1  6   2055808  ultralytics.nn.modules.block.HGBlock         [1024, 192, 1024, 5, 6, True, True]\n  8                  -1  1     11264  ultralytics.nn.modules.conv.DWConv           [1024, 1024, 3, 2, 1, False]  \n  9                  -1  6   6708480  ultralytics.nn.modules.block.HGBlock         [1024, 384, 2048, 5, 6, True, False]\n 10                  -1  1    524800  ultralytics.nn.modules.conv.Conv             [2048, 256, 1, 1, None, 1, 1, False]\n 11                  -1  1    789760  ultralytics.nn.modules.transformer.AIFI      [256, 1024, 8]                \n 12                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14                   7  1    262656  ultralytics.nn.modules.conv.Conv             [1024, 256, 1, 1, None, 1, 1, False]\n 15            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 17                  -1  1     66048  ultralytics.nn.modules.conv.Conv             [256, 256, 1, 1]              \n 18                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 19                   3  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1, None, 1, 1, False]\n 20            [-2, -1]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 22                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 23            [-1, 17]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 24                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 25                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n 26            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 27                  -1  3   2232320  ultralytics.nn.modules.block.RepC3           [512, 256, 3]                 \n 28        [21, 24, 27]  1   7303907  ultralytics.nn.modules.head.RTDETRDecoder    [1, [256, 256, 256]]          \nrt-detr-l summary: 465 layers, 32,808,131 parameters, 32,808,131 gradients, 108.0 GFLOPs\n\nTransferred 926/941 items from pretrained weights\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2244.2Â±410.2 MB/s, size: 213.9 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/flood_yolo/labels/train.cache... 1529 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1529/1529 337.5Mit/s 0.0s\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/flood_yolo/images/train/flood_image0407_3.png: 1 duplicate labels removed\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 790.3Â±633.0 MB/s, size: 351.0 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/flood_yolo/labels/val.cache... 542 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 542/542 19.6Mit/s 0.0s\nPlotting labels to /kaggle/working/runs/detect/train13/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 143 weight(decay=0.0), 206 weight(decay=0.0005), 226 bias(decay=0.0)\nImage sizes 960 train, 960 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/train13\u001b[0m\nStarting training for 100 epochs...\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      1/100      6.45G      2.488     0.2359     0.8419        303        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  1.5s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      1/100       6.6G     0.9848     0.3883     0.1752         31        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:51<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.6it/s 25.7s0.4ss\n                   all        542      18562      0.821      0.755      0.771      0.475\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      2/100      7.13G     0.7551     0.3819    0.09128         46        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:46<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.834      0.768      0.784      0.494\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      3/100      7.13G       0.66     0.3852    0.05888        207        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      3/100      7.13G     0.7217      0.383    0.08459         68        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.7s0.4ss\n                   all        542      18562      0.832      0.769      0.783      0.464\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      4/100      7.21G     0.9446     0.3609    0.09103        159        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      4/100      7.22G     0.6975      0.387     0.0779         25        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.839      0.785      0.799      0.518\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      5/100      7.22G     0.8771     0.3781    0.09706        189        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      5/100      7.22G     0.6844     0.3841    0.07516         28        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.841      0.791      0.808      0.522\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      6/100      7.22G     0.6583     0.3661    0.06616        158        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      6/100      7.22G     0.6663     0.3753     0.0748         82        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.861      0.798      0.818       0.54\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      7/100      7.22G      0.799     0.3651    0.07454        244        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4s\n                   all        542      18562      0.858      0.798      0.819       0.54\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      8/100      7.22G     0.8603     0.3733    0.09018        207        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      8/100      7.22G     0.6518     0.3709    0.06961         76        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.853      0.806       0.82      0.542\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K      9/100       7.3G     0.6826     0.3821    0.06601        198        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K      9/100      7.31G     0.6501     0.3761    0.06873         37        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562       0.86      0.808      0.824      0.549\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     10/100      7.31G     0.5762     0.3463    0.08793         75        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     10/100      7.31G     0.6382     0.3736    0.06764         27        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.871      0.804      0.827      0.552\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     11/100      7.31G     0.4795     0.3146    0.04415         96        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     11/100      7.31G      0.621     0.3719    0.06585         49        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.868      0.807      0.826      0.546\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     12/100      7.31G     0.7567     0.3718    0.09947        143        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     12/100      7.31G       0.62     0.3701    0.06536         16        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.865      0.813      0.832      0.559\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     13/100      7.31G      0.758     0.3549    0.08196        232        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     13/100      7.31G     0.6169     0.3695    0.06583         26        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.873      0.814      0.832      0.562\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     14/100      7.31G     0.4789     0.3932    0.04014        163        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     14/100      7.31G     0.6193     0.3697    0.06485         16        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.862      0.817      0.833      0.566\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     15/100      7.31G     0.5457     0.3392    0.05827        141        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     15/100      7.31G     0.5998     0.3687    0.06185         95        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562       0.86      0.815      0.829      0.551\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     16/100      7.31G     0.5634     0.3584    0.08887        163        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     16/100      7.31G      0.632      0.375    0.06624         17        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.858      0.821      0.832      0.556\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     17/100      7.31G     0.5594     0.3776    0.06704        256        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     17/100      7.31G     0.6115     0.3681    0.06307         41        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.871      0.821      0.833      0.565\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     18/100      7.31G      0.608     0.3683    0.06288         31        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.876       0.82       0.84      0.566\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     19/100      7.31G      0.621      0.368    0.06264         75        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.865      0.812      0.827      0.543\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     20/100      7.31G     0.5143      0.372    0.03329        191        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     20/100      7.31G     0.6031     0.3646    0.06297         25        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.859      0.818      0.828      0.558\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     21/100      7.31G      0.447     0.3489    0.05088        144        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     21/100      7.31G     0.5914     0.3636    0.05978         16        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.862      0.826      0.836      0.574\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     22/100      7.31G     0.5574     0.3637    0.05371        161        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     22/100      7.31G     0.5915     0.3657    0.06042         26        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.869      0.821      0.833      0.572\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     23/100      7.31G     0.5579     0.3619    0.06919        182        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     23/100      7.31G     0.5969     0.3641    0.06119         53        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562       0.86      0.826      0.835      0.567\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     24/100      7.31G     0.6647     0.3647    0.08236        177        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     24/100      7.31G     0.6042     0.3713    0.06086         53        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.873      0.819      0.834      0.564\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     25/100      7.31G      0.642     0.3921    0.03903        306        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     25/100      7.31G     0.6627     0.3778    0.06041         39        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.849      0.813       0.82      0.502\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     26/100      7.31G     0.6775     0.3925    0.08689        112        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     26/100      7.31G     0.6175     0.3742    0.06113         28        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562       0.87      0.826      0.838      0.571\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     27/100      7.31G     0.4704      0.357    0.06129         81        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.8s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     27/100      7.31G     0.5876     0.3612    0.06198         83        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.871      0.829      0.844      0.579\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     28/100      7.31G     0.5688     0.3895    0.05714        162        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     28/100      7.31G     0.5761     0.3639    0.05994         43        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.857      0.822      0.829      0.569\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     29/100      7.31G     0.6444     0.3725    0.04542        200        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     29/100      7.31G     0.5741     0.3613    0.05951         43        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.7s0.4ss\n                   all        542      18562      0.872      0.825       0.84      0.575\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     30/100      7.31G     0.5498     0.3843    0.03773        197        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     30/100      7.31G     0.5667     0.3604    0.05624         28        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.867      0.827      0.838       0.58\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     31/100      7.31G     0.4537     0.3573    0.05027        151        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     31/100      7.31G     0.5787     0.3619    0.05756         92        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562       0.87      0.829      0.842      0.581\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     32/100      7.31G      0.603       0.38    0.06784        141        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     32/100      7.31G     0.5751      0.359    0.05792         54        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4ss\n                   all        542      18562      0.874      0.832      0.844      0.587\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     33/100      7.31G      0.567     0.3811     0.0516        115        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     33/100      7.31G     0.5921     0.3626    0.05994         55        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:45<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4ss\n                   all        542      18562      0.868      0.827      0.839      0.582\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     34/100      7.31G     0.5705     0.3611    0.05747         36        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4ss\n                   all        542      18562      0.866       0.83       0.84      0.578\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     35/100      7.31G     0.5773     0.3657    0.05894         20        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4ss\n                   all        542      18562      0.867      0.827      0.836      0.578\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     36/100      7.31G     0.5136     0.3687    0.05895        226        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     36/100      7.31G     0.5709     0.3614    0.05727         66        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:45<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.881      0.832      0.846      0.585\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     37/100      7.31G     0.4718     0.3493     0.0487        136        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     37/100      7.31G      0.569     0.3561    0.05759         45        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.7s0.4ss\n                   all        542      18562      0.874      0.831      0.838      0.577\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     38/100      7.31G     0.5175     0.3447    0.07169        155        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     38/100      7.31G     0.5722     0.3615    0.05648         36        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.867      0.829       0.84       0.57\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     39/100      7.31G     0.5115     0.3715    0.06559        146        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     39/100      7.31G     0.5889     0.3638    0.05644         49        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.869      0.833      0.837       0.58\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     40/100      7.31G     0.5681     0.3669    0.04005        162        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     40/100      7.31G     0.5614     0.3565    0.05661         66        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4ss\n                   all        542      18562      0.874       0.83      0.838      0.582\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     41/100      7.31G     0.5087     0.3517    0.04936         91        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     41/100      7.31G     0.5738       0.36    0.05687         25        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4ss\n                   all        542      18562       0.87      0.832      0.843      0.581\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     42/100      7.31G     0.4409     0.3716    0.05248        140        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     42/100      7.31G     0.5777       0.36    0.05868         10        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562       0.87      0.826      0.835      0.581\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     43/100      7.31G     0.4571      0.341    0.05568        130        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     43/100      7.31G     0.5616     0.3583    0.05641         69        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.877      0.835      0.847      0.593\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     44/100      7.31G     0.5199     0.3871     0.0537        142        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     44/100      7.31G     0.5579     0.3575    0.05723         34        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.8s0.4ss\n                   all        542      18562      0.876      0.832      0.846      0.588\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     45/100      7.31G     0.5367     0.3767    0.05292        188        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     45/100      7.31G     0.5632     0.3581    0.05754         36        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.868      0.834      0.838      0.583\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     46/100      7.31G     0.6261     0.3482    0.08815        192        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     46/100      7.31G     0.5482     0.3552    0.05648         50        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.866      0.836       0.84      0.591\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     47/100      7.31G     0.6926     0.3616    0.08417        161        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     47/100      7.31G     0.5661     0.3561    0.05598         65        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.876      0.839      0.849      0.596\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     48/100      7.31G     0.3698     0.2847    0.04098         95        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     48/100      7.31G     0.5532     0.3545    0.05307         47        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.874      0.841      0.847      0.591\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     49/100      7.31G     0.5121     0.3708    0.05069        132        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     49/100      7.31G     0.5696     0.3605    0.05628         93        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.876      0.834      0.837      0.577\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     50/100      7.31G     0.5532     0.3542    0.05486         32        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.881      0.838      0.848      0.593\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     51/100      7.31G     0.5579     0.3548    0.05456         20        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 24.7s0.4ss\n                   all        542      18562      0.873      0.837      0.845      0.593\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     52/100      7.31G     0.5265     0.3332    0.05297        201        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     52/100      7.31G     0.5396     0.3536    0.05304         41        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.3it/s 4:44<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.878      0.838      0.845      0.595\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     53/100      7.31G     0.4661     0.3404    0.03664        251        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     53/100      7.31G     0.5395     0.3486    0.05275         41        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.883      0.838      0.849      0.601\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     54/100      7.31G     0.4861      0.359    0.05327        193        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     54/100      7.31G      0.544     0.3501    0.05399         26        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.877       0.84      0.848      0.597\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     55/100      7.31G     0.6367     0.3723    0.04669        177        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     55/100      7.31G     0.5444     0.3508     0.0534         57        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562       0.88       0.84      0.852      0.601\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     56/100      7.31G     0.5167     0.3499    0.05017        247        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     56/100      7.31G     0.5301      0.347    0.05257         39        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.884      0.845       0.85        0.6\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     57/100      7.31G     0.3938       0.32    0.05181        128        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     57/100      7.31G     0.5385      0.347    0.05301         61        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.882       0.84       0.85      0.602\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     58/100      7.31G     0.4543     0.3638    0.03535        181        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     58/100      7.31G     0.5318     0.3477    0.05258         33        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562       0.88      0.841      0.847        0.6\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     59/100      7.31G     0.4956     0.3352    0.04625        169        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     59/100      7.31G     0.5342     0.3456    0.05274         56        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881       0.84       0.85      0.604\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     60/100      7.31G     0.6077     0.3449    0.08767        146        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     60/100      7.31G     0.5315      0.347    0.05303         24        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881      0.844       0.85      0.605\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     61/100      7.31G     0.4634     0.3636    0.04146        120        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     61/100      7.31G     0.5528      0.357    0.05444         47        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562       0.87       0.83      0.837      0.575\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     62/100      7.31G     0.5234     0.3406    0.06407         69        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     62/100      7.31G     0.5548     0.3546    0.05544         39        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.885      0.846      0.851      0.606\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     63/100      7.31G      0.382     0.3269    0.03965        139        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     63/100      7.31G     0.5402     0.3502    0.05364         12        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.877       0.84      0.846      0.599\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     64/100      7.31G     0.6559     0.3533    0.07553        175        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     64/100      7.31G     0.5233     0.3469    0.05258         69        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.873      0.845      0.845      0.599\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     65/100      7.31G     0.4221     0.3579    0.03357         99        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     65/100      7.31G     0.5357     0.3454    0.05295         25        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.874       0.84      0.844      0.601\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     66/100      7.31G     0.5257     0.3424    0.05208         73        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.879      0.839      0.846      0.604\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     67/100      7.31G     0.5537     0.3467    0.05735         17        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.874      0.839      0.845      0.603\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     68/100      7.31G     0.4874     0.3526    0.03579        121        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     68/100      7.31G     0.5435     0.3459    0.05553        126        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.876      0.843      0.849      0.605\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     69/100      7.31G     0.4617     0.3501    0.03133        156        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     69/100      7.31G     0.5356     0.3475    0.05448         24        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.872       0.84      0.847      0.597\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     70/100      7.31G     0.5373     0.3566    0.05635        161        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     70/100      7.31G     0.5472     0.3482     0.0541         28        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562       0.88      0.842      0.849      0.604\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     71/100      7.31G     0.4898     0.3594    0.03041        147        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     71/100      7.31G     0.5299      0.347    0.05287         34        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.875      0.837      0.848      0.598\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     72/100      7.31G     0.6046     0.3577    0.05328        149        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     72/100      7.31G     0.5291     0.3492    0.05254         21        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.888      0.841      0.855       0.61\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     73/100      7.31G      0.493     0.3397    0.05005        208        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     73/100      7.31G     0.5217     0.3446    0.05238         29        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881      0.846      0.851      0.609\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     74/100      7.31G      0.549     0.3857    0.07144        109        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     74/100      7.31G     0.5137     0.3434    0.05077         59        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.884      0.845      0.852      0.608\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     75/100      7.31G     0.5862     0.3414    0.05336        197        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     75/100      7.31G     0.5084     0.3391    0.04965         30        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881       0.85      0.855      0.616\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     76/100      7.31G     0.6305     0.3582    0.05271        206        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     76/100      7.31G     0.5201     0.3413    0.05128         43        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881      0.848      0.852      0.613\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     77/100      7.31G     0.4452     0.3232    0.03612        113        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     77/100      7.31G     0.5147     0.3391    0.05118         60        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881      0.842      0.847      0.607\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     78/100      7.31G     0.5074     0.3401    0.08651        105        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     78/100      7.31G     0.5237     0.3405    0.05155         59        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.879      0.846      0.849      0.611\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     79/100      7.31G      0.546     0.3543    0.04557        222        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     79/100      7.31G     0.5071     0.3425    0.05006         19        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562       0.88      0.844      0.852      0.612\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     80/100      7.31G      0.395      0.312    0.03635        162        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     80/100      7.31G     0.5105     0.3411    0.05045         50        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:43<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.7s0.4ss\n                   all        542      18562      0.884      0.847      0.853      0.611\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     81/100      7.31G     0.4316     0.3567    0.03796        138        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     81/100      7.31G     0.5149     0.3396    0.05056         77        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881      0.847      0.851      0.611\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     82/100      7.31G     0.5115     0.3359    0.05077         14        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.883      0.847      0.853      0.612\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     83/100      7.31G     0.5034     0.3374    0.04797         21        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.888      0.847      0.854      0.615\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     84/100      7.31G     0.7295     0.3533    0.07933        182        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     84/100      7.31G     0.5007     0.3354    0.04945         20        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.889      0.849      0.857      0.619\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     85/100      7.31G     0.7477     0.3434    0.05128        131        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     85/100      7.31G     0.5057      0.336    0.04893         24        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.887      0.847      0.854      0.616\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     86/100      7.31G      0.583     0.3415    0.04697        195        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     86/100      7.31G     0.4934      0.334    0.04773         10        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.887      0.846      0.854      0.615\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     87/100      7.31G     0.4943     0.3393    0.05412        141        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     87/100      7.31G     0.4942     0.3332    0.04787         31        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.886      0.853      0.857      0.619\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     88/100      7.31G     0.4036     0.3286    0.04813         94        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     88/100      7.31G     0.5074     0.3348       0.05         65        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.886      0.849      0.857      0.618\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     89/100      7.31G     0.5158     0.3555    0.03417        162        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     89/100      7.31G      0.498     0.3349    0.04894         47        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.888      0.849      0.855      0.617\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     90/100      7.31G     0.5248      0.347    0.05572        227        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     90/100      7.31G     0.4975     0.3337    0.04783         54        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.895       0.85      0.859      0.622\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     91/100      7.31G     0.6507     0.3402    0.08057        131        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  1.0s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     91/100      7.31G     0.4769     0.3339    0.04803         28        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:42<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.892      0.848      0.856       0.62\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     92/100      7.31G     0.5223      0.314    0.05723         95        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     92/100      7.31G     0.4739     0.3314    0.04781         30        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.881      0.847      0.855      0.612\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     93/100      7.31G     0.5684     0.3705    0.07399        130        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     93/100      7.31G     0.4681     0.3306    0.04681         42        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:40<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.889       0.85      0.859      0.622\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     94/100      7.31G     0.5109     0.3348    0.03778         87        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     94/100      7.31G     0.4618     0.3281    0.04573         23        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:41<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.886      0.851      0.854      0.616\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     95/100      7.31G     0.4641     0.3428    0.04464        120        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     95/100      7.31G     0.4628      0.328    0.04683         32        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:40<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.888      0.851      0.855      0.618\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     96/100      7.31G     0.5163       0.32    0.05536        141        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     96/100      7.31G     0.4676     0.3277    0.04742         16        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:40<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.884      0.851      0.853      0.617\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K     97/100      7.31G     0.4543     0.3683    0.03702        120        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     97/100      7.31G     0.4723     0.3281    0.04688         39        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:40<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.892      0.849      0.855      0.619\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     98/100      7.31G     0.4662     0.3294    0.04669         29        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:40<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.6s0.4ss\n                   all        542      18562      0.888       0.85      0.854      0.614\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K     99/100      7.31G     0.4676     0.3286    0.04638         24        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:40<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.892      0.852      0.856       0.62\n\n      Epoch    GPU_mem  giou_loss   cls_loss    l1_loss  Instances       Size\n\u001b[K    100/100      7.31G      0.374     0.3162    0.04019        119        960: 0% â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ 0/383  0.7s","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: grid_sampler_2d_backward_cuda does not have a deterministic implementation, but you set 'torch.use_deterministic_algorithms(True, warn_only=True)'. You can file an issue at https://github.com/pytorch/pytorch/issues to help us prioritize adding deterministic support for this operation. (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:92.)\n  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n","output_type":"stream"},{"name":"stdout","text":"\u001b[K    100/100      7.31G     0.4605     0.3239    0.04648         31        960: 100% â”â”â”â”â”â”â”â”â”â”â”â” 383/383 1.4it/s 4:40<0.6s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.8it/s 24.5s0.4ss\n                   all        542      18562      0.889      0.854      0.858      0.622\n\n100 epochs completed in 8.573 hours.\nOptimizer stripped from /kaggle/working/runs/detect/train13/weights/last.pt, 66.3MB\nOptimizer stripped from /kaggle/working/runs/detect/train13/weights/best.pt, 66.3MB\n\nValidating /kaggle/working/runs/detect/train13/weights/best.pt...\nUltralytics 8.3.252 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 310 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 68/68 2.7it/s 25.4s0.4ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        542      18562      0.896       0.85      0.859      0.622\nSpeed: 0.4ms preprocess, 39.4ms inference, 0.0ms loss, 0.4ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/train13\u001b[0m\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#  Get path from results object\nbest_model_path = os.path.join(results.save_dir, \"weights\", \"best.pt\")\n\n# Copy to a fixed known location\nshutil.copy(best_model_path, \"/kaggle/working/flood_finetuned_best.pt\")\nprint(\"Finetuned model saved to /kaggle/working/flood_finetuned_best.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T15:48:11.697720Z","iopub.execute_input":"2026-01-12T15:48:11.698218Z","iopub.status.idle":"2026-01-12T15:48:11.772149Z","shell.execute_reply.started":"2026-01-12T15:48:11.698184Z","shell.execute_reply":"2026-01-12T15:48:11.771571Z"}},"outputs":[{"name":"stdout","text":"Finetuned model saved to /kaggle/working/flood_finetuned_best.pt\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Performance on val set\n# -------------------------------\n# Load the best model\nfv_model = YOLO(\"/kaggle/working/flood_finetuned_best.pt\")\n\n# Validate on the flood val set again\nfv_metrics = fv_model.val(data=os.path.join(work_dir, \"flood.yaml\"), split=\"val\", imgsz=960, batch=4)\n\n# Extract metrics\nfv_precision = fv_metrics.box.mp\nfv_recall    = fv_metrics.box.mr\nfv_map50     = fv_metrics.box.map50\nfv_map5095   = fv_metrics.box.map\n\nprint(f\"Precision: {fv_precision:.4f}\")\nprint(f\"Recall: {fv_recall:.4f}\")\nprint(f\"mAP@0.5: {fv_map50:.4f}\")\nprint(f\"mAP@0.5:0.95: {fv_map5095:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T15:48:11.772820Z","iopub.execute_input":"2026-01-12T15:48:11.773027Z","iopub.status.idle":"2026-01-12T15:48:43.465215Z","shell.execute_reply.started":"2026-01-12T15:48:11.773010Z","shell.execute_reply":"2026-01-12T15:48:43.464336Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.252 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 310 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 3304.6Â±886.1 MB/s, size: 856.0 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/flood_yolo/labels/val.cache... 542 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 542/542 227.3Mit/s 0.0s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 136/136 5.0it/s 27.0s0.2s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        542      18562      0.895      0.853      0.861      0.637\nSpeed: 1.7ms preprocess, 43.3ms inference, 0.0ms loss, 0.4ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val4\u001b[0m\nPrecision: 0.8949\nRecall: 0.8529\nmAP@0.5: 0.8612\nmAP@0.5:0.95: 0.6373\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# ===============================\n# Save val metrics to Excel\n# ===============================\n\nmetrics_dict = {\n    \"Precision\": fv_metrics.box.mp,\n    \"Recall\": fv_metrics.box.mr,\n    \"mAP@0.5\": fv_metrics.box.map50,\n    \"mAP@0.5:0.95\": fv_metrics.box.map,\n}\n\nmetrics_df = pd.DataFrame([metrics_dict])\n\n# output directory (same work_dir you already use)\nmetrics_dir = os.path.join(work_dir, \"metrics\")\nos.makedirs(metrics_dir, exist_ok=True)\n\nexcel_path = os.path.join(metrics_dir, \"rt_detr_val_metrics.xlsx\")\nmetrics_df.to_excel(excel_path, index=False)\n\nprint(f\"Metrics saved to: {excel_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T15:48:43.466340Z","iopub.execute_input":"2026-01-12T15:48:43.466670Z","iopub.status.idle":"2026-01-12T15:48:43.858182Z","shell.execute_reply.started":"2026-01-12T15:48:43.466639Z","shell.execute_reply":"2026-01-12T15:48:43.857561Z"}},"outputs":[{"name":"stdout","text":"Metrics saved to: /kaggle/working/flood_yolo/metrics/rt_detr_val_metrics.xlsx\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Performance on test set\n# -------------------------------\n# Load the best model\nft_model = YOLO(\"/kaggle/working/flood_finetuned_best.pt\")\n\n# Validate on the flood val set again\nft_metrics = ft_model.val(data=os.path.join(work_dir, \"flood.yaml\"), split=\"test\", imgsz=960, batch=4)\n\n# Extract metrics\nft_precision = ft_metrics.box.mp\nft_recall    = ft_metrics.box.mr\nft_map50     = ft_metrics.box.map50\nft_map5095   = ft_metrics.box.map\n\nprint(f\"Precision: {ft_precision:.4f}\")\nprint(f\"Recall: {ft_recall:.4f}\")\nprint(f\"mAP@0.5: {ft_map50:.4f}\")\nprint(f\"mAP@0.5:0.95: {ft_map5095:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T15:48:43.860454Z","iopub.execute_input":"2026-01-12T15:48:43.860892Z","iopub.status.idle":"2026-01-12T15:48:55.913757Z","shell.execute_reply.started":"2026-01-12T15:48:43.860872Z","shell.execute_reply":"2026-01-12T15:48:55.913062Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.252 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla P100-PCIE-16GB, 16269MiB)\nrt-detr-l summary: 310 layers, 31,985,795 parameters, 0 gradients, 103.4 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 2747.1Â±655.5 MB/s, size: 556.2 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/flood_yolo/labels/test... 130 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 130/130 1.1Kit/s 0.1s<0.1s\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/flood_yolo/labels/test.cache\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 33/33 4.5it/s 7.4s0.2s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        130       4470      0.897      0.856       0.87      0.646\nSpeed: 2.7ms preprocess, 48.2ms inference, 0.0ms loss, 0.4ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/val5\u001b[0m\nPrecision: 0.8969\nRecall: 0.8563\nmAP@0.5: 0.8697\nmAP@0.5:0.95: 0.6460\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n# ===============================\n# Save test metrics to Excel\n# ===============================\n\nmetrics_dict = {\n    \"Precision\": ft_metrics.box.mp,\n    \"Recall\": ft_metrics.box.mr,\n    \"mAP@0.5\": ft_metrics.box.map50,\n    \"mAP@0.5:0.95\": ft_metrics.box.map,\n}\n\nmetrics_df = pd.DataFrame([metrics_dict])\n\n# output directory (same work_dir you already use)\nmetrics_dir = os.path.join(work_dir, \"metrics\")\nos.makedirs(metrics_dir, exist_ok=True)\n\nexcel_path = os.path.join(metrics_dir, \"rt_detr_test_metrics.xlsx\")\nmetrics_df.to_excel(excel_path, index=False)\n\nprint(f\"Metrics saved to: {excel_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T15:48:55.914643Z","iopub.execute_input":"2026-01-12T15:48:55.914857Z","iopub.status.idle":"2026-01-12T15:48:55.933740Z","shell.execute_reply.started":"2026-01-12T15:48:55.914836Z","shell.execute_reply":"2026-01-12T15:48:55.932999Z"}},"outputs":[{"name":"stdout","text":"Metrics saved to: /kaggle/working/flood_yolo/metrics/rt_detr_test_metrics.xlsx\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport os\nimport cv2\n\n# ==================================\n# Save first 20 TEST prediction results\n# ==================================\n\nsave_pred_dir = os.path.join(work_dir, \"predictions\", \"test\")\nos.makedirs(save_pred_dir, exist_ok=True)\n\n# Test images directory\ntest_images_dir = os.path.join(work_dir, \"images/test\")\ntest_images = sorted(os.listdir(test_images_dir))[:20]\n\nfor idx, img_file in enumerate(test_images):\n    img_path = os.path.join(test_images_dir, img_file)\n\n    # Run prediction\n    results = model.predict(\n        source=img_path,\n        conf=0.25,\n        save=False,\n        verbose=False\n    )\n\n    # Render prediction\n    rendered_img = results[0].plot()\n\n    # Convert BGR to RGB for matplotlib\n    rendered_img = cv2.cvtColor(rendered_img, cv2.COLOR_BGR2RGB)\n\n    # Plot\n    plt.figure(figsize=(6, 6))\n    plt.imshow(rendered_img)\n    plt.axis(\"off\")\n\n    base_name = os.path.splitext(img_file)[0]\n\n    png_path = os.path.join(save_pred_dir, f\"{base_name}.png\")\n    eps_path = os.path.join(save_pred_dir, f\"{base_name}.eps\")\n\n    plt.savefig(png_path, dpi=300, bbox_inches=\"tight\")\n    plt.savefig(eps_path, format=\"eps\", bbox_inches=\"tight\")\n    plt.close()\n\n    print(f\"[{idx+1}/{len(test_images)}] Saved TEST prediction: {png_path} and {eps_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T15:48:55.934593Z","iopub.execute_input":"2026-01-12T15:48:55.934823Z","iopub.status.idle":"2026-01-12T15:49:07.109019Z","shell.execute_reply.started":"2026-01-12T15:48:55.934790Z","shell.execute_reply":"2026-01-12T15:49:07.108338Z"}},"outputs":[{"name":"stdout","text":"[1/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0001_2.png and /kaggle/working/flood_yolo/predictions/test/flood_image0001_2.eps\n[2/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0001_4.png and /kaggle/working/flood_yolo/predictions/test/flood_image0001_4.eps\n[3/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0004_1.png and /kaggle/working/flood_yolo/predictions/test/flood_image0004_1.eps\n[4/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0007_2.png and /kaggle/working/flood_yolo/predictions/test/flood_image0007_2.eps\n[5/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0009_4.png and /kaggle/working/flood_yolo/predictions/test/flood_image0009_4.eps\n[6/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0013_4.png and /kaggle/working/flood_yolo/predictions/test/flood_image0013_4.eps\n[7/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0017_1.png and /kaggle/working/flood_yolo/predictions/test/flood_image0017_1.eps\n[8/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0036_1.png and /kaggle/working/flood_yolo/predictions/test/flood_image0036_1.eps\n[9/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0037_2.png and /kaggle/working/flood_yolo/predictions/test/flood_image0037_2.eps\n[10/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0041_0.png and /kaggle/working/flood_yolo/predictions/test/flood_image0041_0.eps\n[11/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0046_2.png and /kaggle/working/flood_yolo/predictions/test/flood_image0046_2.eps\n[12/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0046_3.png and /kaggle/working/flood_yolo/predictions/test/flood_image0046_3.eps\n[13/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0048_1.png and /kaggle/working/flood_yolo/predictions/test/flood_image0048_1.eps\n[14/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0048_2.png and /kaggle/working/flood_yolo/predictions/test/flood_image0048_2.eps\n[15/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0052_3.png and /kaggle/working/flood_yolo/predictions/test/flood_image0052_3.eps\n[16/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0054_0.png and /kaggle/working/flood_yolo/predictions/test/flood_image0054_0.eps\n[17/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0056_0.png and /kaggle/working/flood_yolo/predictions/test/flood_image0056_0.eps\n[18/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0056_1.png and /kaggle/working/flood_yolo/predictions/test/flood_image0056_1.eps\n[19/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0063_4.png and /kaggle/working/flood_yolo/predictions/test/flood_image0063_4.eps\n[20/20] Saved TEST prediction: /kaggle/working/flood_yolo/predictions/test/flood_image0070_0.png and /kaggle/working/flood_yolo/predictions/test/flood_image0070_0.eps\n","output_type":"stream"}],"execution_count":12}]}